"""
Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù€ AACS V0
Ù†Ø¸Ø§Ù… Ø´Ø§Ù…Ù„ Ù„ØªÙˆØ«ÙŠÙ‚ ÙˆØªØ­Ù„ÙŠÙ„ ÙˆÙ…Ù†Ø¹ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª
"""
import json
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum

from .config import Config
from .logger import setup_logger, SecureLogger
from .memory import MemorySystem


class FailureSeverity(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø®Ø·ÙˆØ±Ø© Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class FailureCategory(Enum):
    """ÙØ¦Ø§Øª Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª"""
    TECHNICAL = "technical"
    BUSINESS = "business"
    COMMUNICATION = "communication"
    PLANNING = "planning"
    EXECUTION = "execution"
    RESOURCE = "resource"
    MARKET = "market"
    UNKNOWN = "unknown"


@dataclass
class FailurePattern:
    """Ù†Ù…Ø· Ø¥Ø®ÙØ§Ù‚ Ù…Ø­Ø¯Ø¯"""
    id: str
    title: str
    description: str
    category: FailureCategory
    severity: FailureSeverity
    causes: List[str]
    symptoms: List[str]
    lessons_learned: List[str]
    prevention_strategies: List[str]
    occurrence_count: int
    first_occurrence: str
    last_occurrence: str
    related_keywords: List[str]
    examples: List[Dict[str, Any]]


@dataclass
class FailureAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ø¥Ø®ÙØ§Ù‚ Ù…Ø­Ø¯Ø¯"""
    failure_id: str
    project_context: Dict[str, Any]
    root_causes: List[str]
    contributing_factors: List[str]
    impact_assessment: Dict[str, Any]
    similar_patterns: List[str]
    recommendations: List[str]
    confidence_score: float


class FailureLibrary:
    """Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
    
    def __init__(self, config: Config, memory_system: MemorySystem):
        self.config = config
        self.memory_system = memory_system
        self.logger = SecureLogger(setup_logger("failure_library"))
        
        # Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ†
        self.base_path = Path("memory/failures")
        self.patterns_file = self.base_path / "patterns.json"
        self.analysis_path = self.base_path / "analysis"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        self._ensure_directories()
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        self.failure_patterns = self._load_failure_patterns()
        
        # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª
        self.failure_keywords = {
            "technical": ["Ø®Ø·Ø£", "Ø¹Ø·Ù„", "ÙØ´Ù„", "Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ©", "Ø¨Ø§Øº", "crash", "error"],
            "business": ["Ø®Ø³Ø§Ø±Ø©", "ÙØ´Ù„ ØªØ¬Ø§Ø±ÙŠ", "Ø¹Ø¯Ù… Ø±Ø¨Ø­ÙŠØ©", "Ù…Ù†Ø§ÙØ³Ø©", "Ø³ÙˆÙ‚"],
            "communication": ["Ø³ÙˆØ¡ ÙÙ‡Ù…", "ØªÙˆØ§ØµÙ„ Ø¶Ø¹ÙŠÙ", "Ø¹Ø¯Ù… ÙˆØ¶ÙˆØ­", "ØªØ¶Ø§Ø±Ø¨"],
            "planning": ["ØªØ®Ø·ÙŠØ· Ø³ÙŠØ¡", "ØªÙ‚Ø¯ÙŠØ± Ø®Ø§Ø·Ø¦", "Ø¬Ø¯ÙˆÙ„Ø©", "Ù…ÙˆØ§Ø±Ø¯"],
            "execution": ["ØªÙ†ÙÙŠØ° Ø¶Ø¹ÙŠÙ", "ØªØ£Ø®ÙŠØ±", "Ø¬ÙˆØ¯Ø© Ù…Ù†Ø®ÙØ¶Ø©", "Ø£Ø¯Ø§Ø¡"],
            "resource": ["Ù†Ù‚Øµ Ù…ÙˆØ§Ø±Ø¯", "Ù…ÙŠØ²Ø§Ù†ÙŠØ©", "ÙˆÙ‚Øª", "ÙØ±ÙŠÙ‚"],
            "market": ["Ø·Ù„Ø¨ Ù…Ù†Ø®ÙØ¶", "Ù…Ù†Ø§ÙØ³Ø© Ø´Ø¯ÙŠØ¯Ø©", "ØªÙˆÙ‚ÙŠØª Ø³ÙŠØ¡", "Ø¬Ù…Ù‡ÙˆØ±"]
        }
        
        self.logger.info("ğŸ“š ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª")
    
    def _ensure_directories(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        self.base_path.mkdir(parents=True, exist_ok=True)
        self.analysis_path.mkdir(parents=True, exist_ok=True)
    
    def _load_failure_patterns(self) -> Dict[str, FailurePattern]:
        """ØªØ­Ù…ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©"""
        if not self.patterns_file.exists():
            return {}
        
        try:
            with open(self.patterns_file, 'r', encoding='utf-8') as f:
                patterns_data = json.load(f)
            
            patterns = {}
            for pattern_id, pattern_data in patterns_data.items():
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† FailurePattern
                pattern_data['category'] = FailureCategory(pattern_data['category'])
                pattern_data['severity'] = FailureSeverity(pattern_data['severity'])
                patterns[pattern_id] = FailurePattern(**pattern_data)
            
            self.logger.info(f"ğŸ“– ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(patterns)} Ù†Ù…Ø· Ø¥Ø®ÙØ§Ù‚")
            return patterns
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª: {e}")
            return {}
    
    def _save_failure_patterns(self):
        """Ø­ÙØ¸ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª"""
        try:
            patterns_data = {}
            for pattern_id, pattern in self.failure_patterns.items():
                pattern_dict = asdict(pattern)
                pattern_dict['category'] = pattern.category.value
                pattern_dict['severity'] = pattern.severity.value
                patterns_data[pattern_id] = pattern_dict
            
            with open(self.patterns_file, 'w', encoding='utf-8') as f:
                json.dump(patterns_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(patterns_data)} Ù†Ù…Ø· Ø¥Ø®ÙØ§Ù‚")
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª: {e}")
    
    def document_failure(self, failure_data: Dict[str, Any]) -> str:
        """ØªÙˆØ«ÙŠÙ‚ Ø¥Ø®ÙØ§Ù‚ Ø¬Ø¯ÙŠØ¯ ÙˆØªØ­Ù„ÙŠÙ„Ù‡"""
        try:
            self.logger.info("ğŸ“ ØªÙˆØ«ÙŠÙ‚ Ø¥Ø®ÙØ§Ù‚ Ø¬Ø¯ÙŠØ¯")
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø®ÙØ§Ù‚
            analysis = self._analyze_failure(failure_data)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ù…Ø´Ø§Ø¨Ù‡Ø©
            similar_patterns = self._find_similar_patterns(failure_data)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø£Ùˆ ØªØ­Ø¯ÙŠØ« Ù†Ù…Ø· Ø§Ù„Ø¥Ø®ÙØ§Ù‚
            pattern_id = self._create_or_update_pattern(failure_data, analysis, similar_patterns)
            
            # Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„
            self._save_failure_analysis(analysis)
            
            # Ø­ÙØ¸ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            self.memory_system.store_failure({
                "pattern_id": pattern_id,
                "analysis": asdict(analysis),
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "severity": analysis.impact_assessment.get("severity", "medium"),
                "category": self._categorize_failure(failure_data).value
            })
            
            self.logger.info(f"âœ… ØªÙ… ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ø¥Ø®ÙØ§Ù‚: {pattern_id}")
            return pattern_id
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ø¥Ø®ÙØ§Ù‚: {e}")
            return ""
    
    def _analyze_failure(self, failure_data: Dict[str, Any]) -> FailureAnalysis:
        """ØªØ­Ù„ÙŠÙ„ Ø¥Ø®ÙØ§Ù‚ Ù…Ø­Ø¯Ø¯"""
        failure_id = f"failure_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³ÙŠØ§Ù‚
        project_context = failure_data.get("project_context", {})
        description = failure_data.get("description", "")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠØ©
        root_causes = self._extract_root_causes(description, project_context)
        
        # Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©
        contributing_factors = self._identify_contributing_factors(failure_data)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ£Ø«ÙŠØ±
        impact_assessment = self._assess_impact(failure_data)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ù…Ø´Ø§Ø¨Ù‡Ø©
        similar_patterns = self._find_similar_patterns(failure_data)
        
        # ØªÙˆØµÙŠØ§Øª
        recommendations = self._generate_recommendations(root_causes, contributing_factors)
        
        # Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        confidence_score = self._calculate_confidence_score(failure_data, root_causes)
        
        return FailureAnalysis(
            failure_id=failure_id,
            project_context=project_context,
            root_causes=root_causes,
            contributing_factors=contributing_factors,
            impact_assessment=impact_assessment,
            similar_patterns=[p.id for p in similar_patterns],
            recommendations=recommendations,
            confidence_score=confidence_score
        )
    
    def _extract_root_causes(self, description: str, context: Dict[str, Any]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠØ© Ù„Ù„Ø¥Ø®ÙØ§Ù‚"""
        causes = []
        description_lower = description.lower()
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨
        cause_indicators = {
            "ØªØ®Ø·ÙŠØ· Ø¶Ø¹ÙŠÙ": ["Ù„Ù… Ù†Ø®Ø·Ø·", "ØªØ®Ø·ÙŠØ· Ø³ÙŠØ¡", "Ø¹Ø¯Ù… ØªØ®Ø·ÙŠØ·", "ØªÙ‚Ø¯ÙŠØ± Ø®Ø§Ø·Ø¦"],
            "Ù†Ù‚Øµ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯": ["Ù†Ù‚Øµ ÙˆÙ‚Øª", "Ù†Ù‚Øµ Ù…ÙŠØ²Ø§Ù†ÙŠØ©", "Ù†Ù‚Øµ ÙØ±ÙŠÙ‚", "Ù…ÙˆØ§Ø±Ø¯ Ù‚Ù„ÙŠÙ„Ø©"],
            "Ù…Ø´Ø§ÙƒÙ„ ØªÙ‚Ù†ÙŠØ©": ["Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ", "Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ÙƒÙˆØ¯", "Ø¨Ø§Øº", "Ø¹Ø·Ù„ ØªÙ‚Ù†ÙŠ"],
            "Ø³ÙˆØ¡ Ø§Ù„ØªÙˆØ§ØµÙ„": ["Ø³ÙˆØ¡ ÙÙ‡Ù…", "Ø¹Ø¯Ù… ÙˆØ¶ÙˆØ­", "ØªÙˆØ§ØµÙ„ Ø¶Ø¹ÙŠÙ", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†Ø§Ù‚ØµØ©"],
            "ØªØºÙŠÙŠØ± Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª": ["ØªØºÙŠÙŠØ± Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª", "Ù…ØªØ·Ù„Ø¨Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©", "ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø®Ø·Ø©"],
            "Ù…Ù†Ø§ÙØ³Ø© Ø§Ù„Ø³ÙˆÙ‚": ["Ù…Ù†Ø§ÙØ³ Ù‚ÙˆÙŠ", "Ø³ÙˆÙ‚ Ù…Ø´Ø¨Ø¹", "Ù…Ù†Ø§ÙØ³Ø© Ø´Ø¯ÙŠØ¯Ø©"],
            "Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ÙØ±ÙŠÙ‚": ["Ø®Ù„Ø§ÙØ§Øª Ø§Ù„ÙØ±ÙŠÙ‚", "Ù†Ù‚Øµ Ø®Ø¨Ø±Ø©", "Ø¯ÙˆØ±Ø§Ù† Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†"]
        }
        
        for cause, indicators in cause_indicators.items():
            if any(indicator in description_lower for indicator in indicators):
                causes.append(cause)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
        if context.get("budget_exceeded"):
            causes.append("ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©")
        
        if context.get("timeline_exceeded"):
            causes.append("ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ")
        
        if context.get("team_size", 0) < context.get("required_team_size", 1):
            causes.append("Ù†Ù‚Øµ ÙÙŠ Ø­Ø¬Ù… Ø§Ù„ÙØ±ÙŠÙ‚")
        
        return causes if causes else ["Ø³Ø¨Ø¨ ØºÙŠØ± Ù…Ø­Ø¯Ø¯"]
    
    def _identify_contributing_factors(self, failure_data: Dict[str, Any]) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© ÙÙŠ Ø§Ù„Ø¥Ø®ÙØ§Ù‚"""
        factors = []
        
        # Ø¹ÙˆØ§Ù…Ù„ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
        if failure_data.get("external_factors"):
            factors.extend(failure_data["external_factors"])
        
        # Ø¹ÙˆØ§Ù…Ù„ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
        context = failure_data.get("project_context", {})
        
        if context.get("first_time_project"):
            factors.append("Ù…Ø´Ø±ÙˆØ¹ Ø¬Ø¯ÙŠØ¯ - Ù†Ù‚Øµ Ø§Ù„Ø®Ø¨Ø±Ø©")
        
        if context.get("tight_deadline"):
            factors.append("Ø¬Ø¯ÙˆÙ„ Ø²Ù…Ù†ÙŠ Ø¶ÙŠÙ‚")
        
        if context.get("complex_requirements"):
            factors.append("Ù…ØªØ·Ù„Ø¨Ø§Øª Ù…Ø¹Ù‚Ø¯Ø©")
        
        if context.get("limited_budget"):
            factors.append("Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©")
        
        return factors
    
    def _assess_impact(self, failure_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙ‚ÙŠÙŠÙ… ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø®ÙØ§Ù‚"""
        impact = {
            "financial_loss": failure_data.get("financial_impact", 0),
            "time_lost_hours": failure_data.get("time_impact", 0),
            "reputation_impact": failure_data.get("reputation_impact", "low"),
            "team_morale_impact": failure_data.get("morale_impact", "medium"),
            "learning_value": "high",  # ÙƒÙ„ Ø¥Ø®ÙØ§Ù‚ Ù„Ù‡ Ù‚ÙŠÙ…Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ©
            "severity": self._determine_severity(failure_data).value
        }
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        total_impact_score = 0
        
        if impact["financial_loss"] > 1000:
            total_impact_score += 3
        elif impact["financial_loss"] > 100:
            total_impact_score += 2
        elif impact["financial_loss"] > 0:
            total_impact_score += 1
        
        if impact["time_lost_hours"] > 40:
            total_impact_score += 3
        elif impact["time_lost_hours"] > 8:
            total_impact_score += 2
        elif impact["time_lost_hours"] > 0:
            total_impact_score += 1
        
        impact["total_impact_score"] = total_impact_score
        
        return impact
    
    def _determine_severity(self, failure_data: Dict[str, Any]) -> FailureSeverity:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø®Ø·ÙˆØ±Ø© Ø§Ù„Ø¥Ø®ÙØ§Ù‚"""
        financial_impact = failure_data.get("financial_impact", 0)
        time_impact = failure_data.get("time_impact", 0)
        reputation_impact = failure_data.get("reputation_impact", "low")
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø·
        severity_score = 0
        
        if financial_impact > 5000:
            severity_score += 4
        elif financial_impact > 1000:
            severity_score += 3
        elif financial_impact > 100:
            severity_score += 2
        elif financial_impact > 0:
            severity_score += 1
        
        if time_impact > 80:
            severity_score += 3
        elif time_impact > 40:
            severity_score += 2
        elif time_impact > 8:
            severity_score += 1
        
        if reputation_impact == "high":
            severity_score += 3
        elif reputation_impact == "medium":
            severity_score += 2
        elif reputation_impact == "low":
            severity_score += 1
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³ØªÙˆÙ‰
        if severity_score >= 8:
            return FailureSeverity.CRITICAL
        elif severity_score >= 5:
            return FailureSeverity.HIGH
        elif severity_score >= 2:
            return FailureSeverity.MEDIUM
        else:
            return FailureSeverity.LOW
    
    def _categorize_failure(self, failure_data: Dict[str, Any]) -> FailureCategory:
        """ØªØµÙ†ÙŠÙ Ø§Ù„Ø¥Ø®ÙØ§Ù‚"""
        description = failure_data.get("description", "").lower()
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        category_mapping = {
            "technical": FailureCategory.TECHNICAL,
            "business": FailureCategory.BUSINESS,
            "communication": FailureCategory.COMMUNICATION,
            "planning": FailureCategory.PLANNING,
            "execution": FailureCategory.EXECUTION,
            "resource": FailureCategory.RESOURCE,
            "market": FailureCategory.MARKET
        }
        
        for category, keywords in self.failure_keywords.items():
            if any(keyword in description for keyword in keywords):
                return category_mapping.get(category, FailureCategory.UNKNOWN)
        
        # ØªØµÙ†ÙŠÙ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
        context = failure_data.get("project_context", {})
        
        if context.get("technical_project"):
            return FailureCategory.TECHNICAL
        elif context.get("business_project"):
            return FailureCategory.BUSINESS
        
        return FailureCategory.UNKNOWN
    
    def _find_similar_patterns(self, failure_data: Dict[str, Any]) -> List[FailurePattern]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø¥Ø®ÙØ§Ù‚ Ù…Ø´Ø§Ø¨Ù‡Ø©"""
        similar_patterns = []
        description = failure_data.get("description", "").lower()
        category = self._categorize_failure(failure_data)
        
        for pattern in self.failure_patterns.values():
            similarity_score = 0
            
            # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙØ¦Ø©
            if pattern.category == category:
                similarity_score += 3
            
            # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            for keyword in pattern.related_keywords:
                if keyword.lower() in description:
                    similarity_score += 1
            
            # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶
            for symptom in pattern.symptoms:
                if symptom.lower() in description:
                    similarity_score += 2
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©
            if similarity_score >= 3:
                similar_patterns.append(pattern)
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
        return sorted(similar_patterns, 
                     key=lambda p: self._calculate_similarity_score(p, failure_data), 
                     reverse=True)[:5]
    
    def _calculate_similarity_score(self, pattern: FailurePattern, failure_data: Dict[str, Any]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ† Ù†Ù…Ø· ÙˆØ¥Ø®ÙØ§Ù‚"""
        score = 0.0
        description = failure_data.get("description", "").lower()
        
        # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙØ¦Ø© (ÙˆØ²Ù† Ø¹Ø§Ù„ÙŠ)
        if pattern.category == self._categorize_failure(failure_data):
            score += 0.4
        
        # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        keyword_matches = sum(1 for keyword in pattern.related_keywords 
                            if keyword.lower() in description)
        if pattern.related_keywords:
            score += 0.3 * (keyword_matches / len(pattern.related_keywords))
        
        # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶
        symptom_matches = sum(1 for symptom in pattern.symptoms 
                            if symptom.lower() in description)
        if pattern.symptoms:
            score += 0.3 * (symptom_matches / len(pattern.symptoms))
        
        return score
    
    def _generate_recommendations(self, root_causes: List[str], 
                                contributing_factors: List[str]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        recommendations = []
        
        # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠØ©
        cause_recommendations = {
            "ØªØ®Ø·ÙŠØ· Ø¶Ø¹ÙŠÙ": [
                "ØªØ·ÙˆÙŠØ± Ø¹Ù…Ù„ÙŠØ© ØªØ®Ø·ÙŠØ· Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹",
                "Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹",
                "Ø¥Ø´Ø±Ø§Ùƒ Ø®Ø¨Ø±Ø§Ø¡ ÙÙŠ Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ®Ø·ÙŠØ·"
            ],
            "Ù†Ù‚Øµ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯": [
                "ØªØ­Ø³ÙŠÙ† ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©",
                "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø·Ø§Ø±Ø¦Ø©",
                "ØªØ·ÙˆÙŠØ± Ø´Ø±Ø§ÙƒØ§Øª Ù„ØªÙˆÙÙŠØ± Ù…ÙˆØ§Ø±Ø¯ Ø¥Ø¶Ø§ÙÙŠØ©"
            ],
            "Ù…Ø´Ø§ÙƒÙ„ ØªÙ‚Ù†ÙŠØ©": [
                "ØªØ­Ø³ÙŠÙ† Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ù„Ø¬ÙˆØ¯Ø©",
                "Ø§Ø³ØªØ«Ù…Ø§Ø± ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ‚Ù†ÙŠ",
                "Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙˆØ¯"
            ],
            "Ø³ÙˆØ¡ Ø§Ù„ØªÙˆØ§ØµÙ„": [
                "ØªØ­Ø³ÙŠÙ† Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„",
                "Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ«Ø§Ø¦Ù‚ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙØµÙ„Ø©",
                "Ø¹Ù‚Ø¯ Ø§Ø¬ØªÙ…Ø§Ø¹Ø§Øª Ø¯ÙˆØ±ÙŠØ© Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©"
            ]
        }
        
        for cause in root_causes:
            if cause in cause_recommendations:
                recommendations.extend(cause_recommendations[cause])
        
        # ØªÙˆØµÙŠØ§Øª Ø¹Ø§Ù…Ø©
        recommendations.extend([
            "ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø©",
            "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©",
            "ØªØ·ÙˆÙŠØ± Ø®Ø·Ø© Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø´ÙƒÙ„Ø©"
        ])
        
        return list(set(recommendations))  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
    
    def _calculate_confidence_score(self, failure_data: Dict[str, Any], 
                                  root_causes: List[str]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        confidence = 0.5  # Ù‚ÙŠÙ…Ø© Ø£Ø³Ø§Ø³ÙŠØ©
        
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if failure_data.get("description") and len(failure_data["description"]) > 50:
            confidence += 0.2
        
        if failure_data.get("project_context"):
            confidence += 0.1
        
        if failure_data.get("financial_impact") is not None:
            confidence += 0.1
        
        if len(root_causes) > 1:
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def validate_idea_against_failures(self, idea_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÙØ­Øµ ÙÙƒØ±Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        try:
            self.logger.info("ğŸ” ÙØ­Øµ Ø§Ù„ÙÙƒØ±Ø© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©")
            
            idea_description = idea_data.get("description", "").lower()
            idea_category = idea_data.get("category", "")
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¥Ø®ÙØ§Ù‚Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©
            similar_failures = []
            risk_factors = []
            warnings = []
            
            for pattern in self.failure_patterns.values():
                similarity_score = 0
                
                # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
                for keyword in pattern.related_keywords:
                    if keyword.lower() in idea_description:
                        similarity_score += 1
                
                # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙØ¦Ø©
                if pattern.category.value in idea_category.lower():
                    similarity_score += 2
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©
                if similarity_score >= 2:
                    similar_failures.append({
                        "pattern_id": pattern.id,
                        "title": pattern.title,
                        "similarity_score": similarity_score,
                        "occurrence_count": pattern.occurrence_count,
                        "severity": pattern.severity.value,
                        "main_causes": pattern.causes[:3],
                        "prevention_strategies": pattern.prevention_strategies[:3]
                    })
            
            # ØªØ­Ù„ÙŠÙ„ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø®Ø·Ø±
            for failure in similar_failures:
                if failure["occurrence_count"] > 2:
                    risk_factors.append(f"Ù†Ù…Ø· Ù…ØªÙƒØ±Ø±: {failure['title']}")
                
                if failure["severity"] in ["high", "critical"]:
                    warnings.append(f"Ø®Ø·Ø± Ø¹Ø§Ù„ÙŠ: {failure['title']}")
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            risk_level = "low"
            if len(warnings) > 0:
                risk_level = "high"
            elif len(similar_failures) > 2:
                risk_level = "medium"
            
            # ØªÙˆØµÙŠØ§Øª
            recommendations = []
            if similar_failures:
                recommendations.append("Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡")
                recommendations.append("ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø¹ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©")
                
                # Ø¬Ù…Ø¹ Ø£Ù‡Ù… Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø¹
                all_strategies = []
                for failure in similar_failures:
                    all_strategies.extend(failure["prevention_strategies"])
                
                # Ø£ÙƒØ«Ø± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª ØªÙƒØ±Ø§Ø±Ø§Ù‹
                strategy_counts = {}
                for strategy in all_strategies:
                    strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
                
                top_strategies = sorted(strategy_counts.items(), 
                                      key=lambda x: x[1], reverse=True)[:3]
                
                for strategy, count in top_strategies:
                    recommendations.append(f"ØªØ·Ø¨ÙŠÙ‚: {strategy}")
            
            validation_result = {
                "risk_level": risk_level,
                "similar_failures_count": len(similar_failures),
                "similar_failures": similar_failures,
                "risk_factors": risk_factors,
                "warnings": warnings,
                "recommendations": recommendations,
                "validation_timestamp": datetime.now(timezone.utc).isoformat(),
                "should_proceed": len(warnings) == 0,
                "confidence_score": min(0.9, 0.5 + (len(similar_failures) * 0.1))
            }
            
            self.logger.info(f"âœ… ØªÙ… ÙØ­Øµ Ø§Ù„ÙÙƒØ±Ø© - Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±: {risk_level}")
            return validation_result
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ ÙØ­Øµ Ø§Ù„ÙÙƒØ±Ø©: {e}")
            return {
                "risk_level": "unknown",
                "error": str(e),
                "should_proceed": True,
                "confidence_score": 0.0
            }
    
    def search_failures(self, query: str, category: Optional[FailureCategory] = None,
                       severity: Optional[FailureSeverity] = None,
                       limit: int = 10) -> List[FailurePattern]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª"""
        try:
            results = []
            query_lower = query.lower()
            
            for pattern in self.failure_patterns.values():
                # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø© ÙˆØ§Ù„Ø®Ø·ÙˆØ±Ø©
                if category and pattern.category != category:
                    continue
                
                if severity and pattern.severity != severity:
                    continue
                
                # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                score = 0
                
                if query_lower in pattern.title.lower():
                    score += 3
                
                if query_lower in pattern.description.lower():
                    score += 2
                
                for keyword in pattern.related_keywords:
                    if query_lower in keyword.lower():
                        score += 1
                
                for cause in pattern.causes:
                    if query_lower in cause.lower():
                        score += 2
                
                if score > 0:
                    results.append((pattern, score))
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø·
            results.sort(key=lambda x: x[1], reverse=True)
            
            return [pattern for pattern, score in results[:limit]]
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")
            return []
    
    def _create_or_update_pattern(self, failure_data: Dict[str, Any], 
                                analysis: FailureAnalysis, 
                                similar_patterns: List[FailurePattern]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø£Ùˆ ØªØ­Ø¯ÙŠØ« Ù†Ù…Ø· Ø¥Ø®ÙØ§Ù‚"""
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…Ø· Ù…Ø·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹
        exact_match = None
        for pattern in similar_patterns:
            if self._calculate_similarity_score(pattern, failure_data) > 0.8:
                exact_match = pattern
                break
        
        if exact_match:
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
            exact_match.occurrence_count += 1
            exact_match.last_occurrence = datetime.now(timezone.utc).isoformat()
            exact_match.examples.append({
                "failure_id": analysis.failure_id,
                "description": failure_data.get("description", ""),
                "context": failure_data.get("project_context", {}),
                "timestamp": datetime.now(timezone.utc).isoformat()
            })
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø©
            for lesson in analysis.recommendations:
                if lesson not in exact_match.lessons_learned:
                    exact_match.lessons_learned.append(lesson)
            
            pattern_id = exact_match.id
            
        else:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…Ø· Ø¬Ø¯ÙŠØ¯
            pattern_id = f"pattern_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            new_pattern = FailurePattern(
                id=pattern_id,
                title=self._generate_pattern_title(failure_data),
                description=failure_data.get("description", "")[:200] + "...",
                category=self._categorize_failure(failure_data),
                severity=self._determine_severity(failure_data),
                causes=analysis.root_causes,
                symptoms=self._extract_symptoms(failure_data),
                lessons_learned=analysis.recommendations,
                prevention_strategies=self._generate_prevention_strategies(analysis),
                occurrence_count=1,
                first_occurrence=datetime.now(timezone.utc).isoformat(),
                last_occurrence=datetime.now(timezone.utc).isoformat(),
                related_keywords=self._extract_keywords(failure_data),
                examples=[{
                    "failure_id": analysis.failure_id,
                    "description": failure_data.get("description", ""),
                    "context": failure_data.get("project_context", {}),
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }]
            )
            
            self.failure_patterns[pattern_id] = new_pattern
        
        # Ø­ÙØ¸ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
        self._save_failure_patterns()
        
        return pattern_id
    
    def _generate_pattern_title(self, failure_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†ÙˆØ§Ù† Ù„Ù„Ù†Ù…Ø·"""
        category = self._categorize_failure(failure_data)
        description = failure_data.get("description", "")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        keywords = self._extract_keywords(failure_data)
        main_keyword = keywords[0] if keywords else "Ù…Ø´ÙƒÙ„Ø©"
        
        return f"Ø¥Ø®ÙØ§Ù‚ {category.value}: {main_keyword}"
    
    def _extract_symptoms(self, failure_data: Dict[str, Any]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ø¥Ø®ÙØ§Ù‚"""
        symptoms = []
        description = failure_data.get("description", "").lower()
        
        # Ø£Ø¹Ø±Ø§Ø¶ Ø´Ø§Ø¦Ø¹Ø©
        symptom_patterns = {
            "Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø£Ø¯Ø§Ø¡": ["Ø¨Ø·Ø¡", "Ø£Ø¯Ø§Ø¡ Ø¶Ø¹ÙŠÙ", "Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¨Ø·ÙŠØ¦Ø©"],
            "Ø£Ø®Ø·Ø§Ø¡ Ù…ØªÙƒØ±Ø±Ø©": ["Ø®Ø·Ø£ Ù…ØªÙƒØ±Ø±", "Ù…Ø´Ø§ÙƒÙ„ Ù…Ø³ØªÙ…Ø±Ø©", "Ø£Ø¹Ø·Ø§Ù„ Ù…ØªØªØ§Ù„ÙŠØ©"],
            "Ø¹Ø¯Ù… Ø±Ø¶Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†": ["Ø´ÙƒØ§ÙˆÙ‰", "Ø¹Ø¯Ù… Ø±Ø¶Ø§", "ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø³Ù„Ø¨ÙŠØ©"],
            "ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©": ["ØªÙƒÙ„ÙØ© Ø¥Ø¶Ø§ÙÙŠØ©", "ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©", "Ù†ÙÙ‚Ø§Øª Ø²Ø§Ø¦Ø¯Ø©"],
            "ØªØ£Ø®ÙŠØ± ÙÙŠ Ø§Ù„ØªØ³Ù„ÙŠÙ…": ["ØªØ£Ø®ÙŠØ±", "Ø¹Ø¯Ù… Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯", "ØªØ£Ø¬ÙŠÙ„"]
        }
        
        for symptom, patterns in symptom_patterns.items():
            if any(pattern in description for pattern in patterns):
                symptoms.append(symptom)
        
        return symptoms if symptoms else ["Ø£Ø¹Ø±Ø§Ø¶ ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©"]
    
    def _extract_keywords(self, failure_data: Dict[str, Any]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        description = failure_data.get("description", "")
        
        # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
        common_keywords = [
            "ØªØ·Ø¨ÙŠÙ‚", "Ù…ÙˆÙ‚Ø¹", "Ù†Ø¸Ø§Ù…", "Ø£Ø¯Ø§Ø©", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "Ø®Ø¯Ù…Ø©",
            "Ù…Ø´Ø±ÙˆØ¹", "ØªØ·ÙˆÙŠØ±", "ØªØµÙ…ÙŠÙ…", "ØªØ³ÙˆÙŠÙ‚", "Ø¨ÙŠØ¹"
        ]
        
        keywords = []
        for keyword in common_keywords:
            if keyword in description:
                keywords.append(keyword)
        
        # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
        context = failure_data.get("project_context", {})
        if context.get("project_type"):
            keywords.append(context["project_type"])
        
        return keywords[:5]  # Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
    
    def _generate_prevention_strategies(self, analysis: FailureAnalysis) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø¹"""
        strategies = []
        
        # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠØ©
        for cause in analysis.root_causes:
            if "ØªØ®Ø·ÙŠØ·" in cause:
                strategies.append("ØªØ·Ø¨ÙŠÙ‚ Ù…Ù†Ù‡Ø¬ÙŠØ© ØªØ®Ø·ÙŠØ· ØµØ§Ø±Ù…Ø©")
            elif "Ù…ÙˆØ§Ø±Ø¯" in cause:
                strategies.append("ØªØ­Ø³ÙŠÙ† ØªÙ‚Ø¯ÙŠØ± ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ø±Ø¯")
            elif "ØªÙ‚Ù†ÙŠ" in cause:
                strategies.append("ØªØ¹Ø²ÙŠØ² Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©")
            elif "ØªÙˆØ§ØµÙ„" in cause:
                strategies.append("ØªØ­Ø³ÙŠÙ† Ø¢Ù„ÙŠØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ ÙˆØ§Ù„ØªÙˆØ«ÙŠÙ‚")
        
        # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        strategies.extend([
            "Ø¥Ø¬Ø±Ø§Ø¡ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø¯ÙˆØ±ÙŠØ© Ù„Ù„Ù…Ø®Ø§Ø·Ø±",
            "ØªØ·ÙˆÙŠØ± Ø®Ø·Ø· Ø·ÙˆØ§Ø±Ø¦",
            "ØªØ­Ø³ÙŠÙ† Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„ØªØªØ¨Ø¹"
        ])
        
        return list(set(strategies))
    
    def _save_failure_analysis(self, analysis: FailureAnalysis):
        """Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø®ÙØ§Ù‚ Ø§Ù„Ù…ÙØµÙ„"""
        try:
            analysis_file = self.analysis_path / f"{analysis.failure_id}.json"
            
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(asdict(analysis), f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø®ÙØ§Ù‚: {analysis.failure_id}")
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø®ÙØ§Ù‚: {e}")
    
    def get_failure_statistics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª"""
        try:
            total_patterns = len(self.failure_patterns)
            
            if total_patterns == 0:
                return {
                    "total_patterns": 0,
                    "total_occurrences": 0,
                    "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ù†Ù…Ø§Ø· Ø¥Ø®ÙØ§Ù‚ Ù…Ø³Ø¬Ù„Ø©"
                }
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØ¦Ø§Øª
            category_stats = {}
            severity_stats = {}
            total_occurrences = 0
            
            for pattern in self.failure_patterns.values():
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØ¦Ø§Øª
                category = pattern.category.value
                category_stats[category] = category_stats.get(category, 0) + 1
                
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø®Ø·ÙˆØ±Ø©
                severity = pattern.severity.value
                severity_stats[severity] = severity_stats.get(severity, 0) + 1
                
                # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
                total_occurrences += pattern.occurrence_count
            
            # Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ù†Ù…Ø§Ø· ØªÙƒØ±Ø§Ø±Ø§Ù‹
            most_common = sorted(self.failure_patterns.values(), 
                               key=lambda p: p.occurrence_count, reverse=True)[:5]
            
            # Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø®ÙŠØ±Ø©
            recent_patterns = sorted(self.failure_patterns.values(), 
                                   key=lambda p: p.last_occurrence, reverse=True)[:5]
            
            return {
                "total_patterns": total_patterns,
                "total_occurrences": total_occurrences,
                "average_occurrences": round(total_occurrences / total_patterns, 2),
                "category_distribution": category_stats,
                "severity_distribution": severity_stats,
                "most_common_patterns": [
                    {
                        "id": p.id,
                        "title": p.title,
                        "occurrences": p.occurrence_count,
                        "severity": p.severity.value
                    } for p in most_common
                ],
                "recent_patterns": [
                    {
                        "id": p.id,
                        "title": p.title,
                        "last_occurrence": p.last_occurrence,
                        "severity": p.severity.value
                    } for p in recent_patterns
                ]
            }
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª: {e}")
            return {"error": str(e)}