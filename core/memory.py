"""
Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ø§Ø¦Ù… Ù„Ù€ AACS V0
"""
import json
import jsonlines
import os
import shutil
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict

from .config import Config
from .logger import setup_logger, SecureLogger


@dataclass
class MemoryEntry:
    """Ø¥Ø¯Ø®Ø§Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    id: str
    timestamp: str
    type: str  # meeting, decision, reflection, failure, etc.
    content: Dict[str, Any]
    metadata: Dict[str, Any] = None
    tags: List[str] = None


@dataclass
class QueryResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    entries: List[MemoryEntry]
    total_count: int
    query_time_ms: float


class MemorySystem:
    """Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ø§Ø¦Ù…"""
    
    def __init__(self, config: Config):
        self.config = config
        self.logger = SecureLogger(setup_logger("memory"))
        
        # Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ†
        self.base_path = Path("memory")
        self.meetings_path = Path(config.MEETINGS_DIR)
        self.board_path = Path(config.BOARD_DIR)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        self._ensure_directories()
        
        # ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self.memory_index = self._load_memory_index()
        
        self.logger.info("ğŸ§  ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©")
    
    def _ensure_directories(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        directories = [
            self.base_path,
            self.base_path / "meetings",
            self.base_path / "decisions", 
            self.base_path / "reflections",
            self.base_path / "failures",
            self.base_path / "backups",
            self.meetings_path,
            self.board_path
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
    
    def _load_memory_index(self) -> Dict[str, Any]:
        """ØªØ­Ù…ÙŠÙ„ ÙÙ‡Ø±Ø³ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        index_file = self.base_path / "index.json"
        
        if index_file.exists():
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ÙÙ‡Ø±Ø³ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
        
        # ÙÙ‡Ø±Ø³ Ø§ÙØªØ±Ø§Ø¶ÙŠ
        return {
            "version": "1.0",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "last_updated": datetime.now(timezone.utc).isoformat(),
            "entries_count": 0,
            "categories": {
                "meetings": 0,
                "decisions": 0,
                "reflections": 0,
                "failures": 0
            }
        }
    
    def _save_memory_index(self):
        """Ø­ÙØ¸ ÙÙ‡Ø±Ø³ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        index_file = self.base_path / "index.json"
        
        self.memory_index["last_updated"] = datetime.now(timezone.utc).isoformat()
        
        try:
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(self.memory_index, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ ÙÙ‡Ø±Ø³ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
    
    def store_meeting_data(self, session_id: str, meeting_data: Dict[str, Any], 
                          transcript: List[Dict[str, Any]], decisions: List[Dict[str, Any]], 
                          reflections: Dict[str, str]) -> bool:
        """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ø§Ø¦Ù…Ø©"""
        try:
            self.logger.info(f"ğŸ’¾ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹: {session_id}")
            
            # Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            meeting_entry = MemoryEntry(
                id=f"meeting_{session_id}",
                timestamp=datetime.now(timezone.utc).isoformat(),
                type="meeting",
                content={
                    "session_id": session_id,
                    "meeting_data": meeting_data,
                    "transcript_summary": self._summarize_transcript(transcript),
                    "participants": meeting_data.get("participants", []),
                    "agenda": meeting_data.get("agenda", ""),
                    "decisions_count": len(decisions)
                },
                metadata={
                    "source": "meeting_orchestrator",
                    "transcript_length": len(transcript)
                },
                tags=["meeting", "session", session_id]
            )
            
            self._store_entry(meeting_entry, "meetings")
            
            # Ø­ÙØ¸ Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª
            for decision in decisions:
                decision_entry = MemoryEntry(
                    id=f"decision_{decision['id']}",
                    timestamp=datetime.now(timezone.utc).isoformat(),
                    type="decision",
                    content=decision,
                    metadata={
                        "session_id": session_id,
                        "outcome": decision.get("outcome", "unknown")
                    },
                    tags=["decision", session_id, decision.get("outcome", "unknown")]
                )
                
                self._store_entry(decision_entry, "decisions")
            
            # Ø­ÙØ¸ Ø§Ù„ØªØ£Ù…Ù„Ø§Øª Ø§Ù„Ø°Ø§ØªÙŠØ©
            for agent_id, reflection_content in reflections.items():
                reflection_entry = MemoryEntry(
                    id=f"reflection_{session_id}_{agent_id}",
                    timestamp=datetime.now(timezone.utc).isoformat(),
                    type="reflection",
                    content={
                        "agent_id": agent_id,
                        "session_id": session_id,
                        "reflection_text": reflection_content,
                        "extracted_insights": self._extract_reflection_insights(reflection_content)
                    },
                    metadata={
                        "session_id": session_id,
                        "agent_id": agent_id
                    },
                    tags=["reflection", agent_id, session_id]
                )
                
                self._store_entry(reflection_entry, "reflections")
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            self.memory_index["entries_count"] += 1 + len(decisions) + len(reflections)
            self.memory_index["categories"]["meetings"] += 1
            self.memory_index["categories"]["decisions"] += len(decisions)
            self.memory_index["categories"]["reflections"] += len(reflections)
            
            self._save_memory_index()
            
            self.logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ {session_id} Ø¨Ù†Ø¬Ø§Ø­")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ {session_id}: {e}")
            return False
    
    def _store_entry(self, entry: MemoryEntry, category: str):
        """Ø­ÙØ¸ Ø¥Ø¯Ø®Ø§Ù„ ÙÙŠ ÙØ¦Ø© Ù…Ø­Ø¯Ø¯Ø©"""
        category_path = self.base_path / category
        entry_file = category_path / f"{entry.id}.json"
        
        with open(entry_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(entry), f, ensure_ascii=False, indent=2)
    
    def _summarize_transcript(self, transcript: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ØªÙ„Ø®ÙŠØµ Ù…Ø­Ø¶Ø± Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹"""
        if not transcript:
            return {"summary": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­Ø¶Ø±", "message_count": 0}
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø£Ø³Ø§Ø³ÙŠØ©
        message_types = {}
        agent_participation = {}
        
        for entry in transcript:
            msg_type = entry.get("type", "unknown")
            agent = entry.get("agent", "unknown")
            
            message_types[msg_type] = message_types.get(msg_type, 0) + 1
            agent_participation[agent] = agent_participation.get(agent, 0) + 1
        
        return {
            "message_count": len(transcript),
            "message_types": message_types,
            "agent_participation": agent_participation,
            "duration_estimated": f"{len(transcript) * 2} Ø¯Ù‚ÙŠÙ‚Ø©",  # ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ·
            "key_topics": self._extract_key_topics(transcript)
        }
    
    def _extract_key_topics(self, transcript: List[Dict[str, Any]]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø­Ø¶Ø±"""
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ· Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        key_words = set()
        
        for entry in transcript:
            message = entry.get("message", "").lower()
            
            # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
            keywords = ["Ù…Ø´Ø±ÙˆØ¹", "ØªØ·ÙˆÙŠØ±", "Ø£Ø¯Ø§Ø©", "ØªØ·Ø¨ÙŠÙ‚", "Ù†Ø¸Ø§Ù…", "Ù…ÙˆÙ‚Ø¹", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "Ø®Ø¯Ù…Ø©"]
            
            for keyword in keywords:
                if keyword in message:
                    key_words.add(keyword)
        
        return list(key_words)
    
    def _extract_reflection_insights(self, reflection_text: str) -> Dict[str, List[str]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø¤Ù‰ Ù…Ù† ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ£Ù…Ù„ Ø§Ù„Ø°Ø§ØªÙŠ"""
        insights = {
            "successes": [],
            "failures": [],
            "improvements": []
        }
        
        lines = reflection_text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            if "Ù…Ø§ Ù†Ø¬Ø­" in line or "Ù†Ø¬Ø­" in line:
                current_section = "successes"
            elif "Ù…Ø§ ÙØ´Ù„" in line or "ÙØ´Ù„" in line:
                current_section = "failures"
            elif "Ø®Ø·Ø© Ø§Ù„ØªØ­Ø³ÙŠÙ†" in line or "ØªØ­Ø³ÙŠÙ†" in line:
                current_section = "improvements"
            elif current_section and line and not line.startswith('#'):
                insights[current_section].append(line)
        
        return insights
    
    def retrieve_context(self, query: str, limit: int = 10, 
                        entry_types: List[str] = None) -> QueryResult:
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
        start_time = datetime.now()
        
        try:
            entries = []
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø£Ùˆ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª
            search_categories = entry_types or ["meetings", "decisions", "reflections"]
            
            for category in search_categories:
                category_path = self.base_path / category
                
                if not category_path.exists():
                    continue
                
                # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ¦Ø©
                for entry_file in category_path.glob("*.json"):
                    try:
                        with open(entry_file, 'r', encoding='utf-8') as f:
                            entry_data = json.load(f)
                            entry = MemoryEntry(**entry_data)
                            
                            # ÙØ­Øµ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
                            if self._matches_query(entry, query):
                                entries.append(entry)
                    
                    except Exception as e:
                        self.logger.warning(f"ÙØ´Ù„ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {entry_file}: {e}")
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
            entries.sort(key=lambda x: x.timestamp, reverse=True)
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            limited_entries = entries[:limit]
            
            query_time = (datetime.now() - start_time).total_seconds() * 1000
            
            return QueryResult(
                entries=limited_entries,
                total_count=len(entries),
                query_time_ms=query_time
            )
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚: {e}")
            return QueryResult(entries=[], total_count=0, query_time_ms=0)
    
    def _matches_query(self, entry: MemoryEntry, query: str) -> bool:
        """ÙØ­Øµ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
        query_lower = query.lower()
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        content_str = json.dumps(entry.content, ensure_ascii=False).lower()
        if query_lower in content_str:
            return True
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª
        if entry.tags:
            for tag in entry.tags:
                if query_lower in tag.lower():
                    return True
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†ÙˆØ¹
        if query_lower in entry.type.lower():
            return True
        
        return False
    
    def store_failure(self, failure_data: Dict[str, Any]) -> bool:
        """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø®ÙØ§Ù‚ Ù„Ù„ØªØ¹Ù„Ù…"""
        try:
            failure_entry = MemoryEntry(
                id=f"failure_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                timestamp=datetime.now(timezone.utc).isoformat(),
                type="failure",
                content=failure_data,
                metadata={
                    "severity": failure_data.get("severity", "medium"),
                    "category": failure_data.get("category", "unknown")
                },
                tags=["failure", failure_data.get("category", "unknown")]
            )
            
            self._store_entry(failure_entry, "failures")
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            self.memory_index["entries_count"] += 1
            self.memory_index["categories"]["failures"] += 1
            self._save_memory_index()
            
            self.logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø®ÙØ§Ù‚: {failure_entry.id}")
            return True
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø®ÙØ§Ù‚: {e}")
            return False
    
    def get_failure_patterns(self) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        try:
            failures_path = self.base_path / "failures"
            patterns = []
            
            if not failures_path.exists():
                return patterns
            
            for failure_file in failures_path.glob("*.json"):
                try:
                    with open(failure_file, 'r', encoding='utf-8') as f:
                        failure_data = json.load(f)
                        patterns.append(failure_data["content"])
                
                except Exception as e:
                    self.logger.warning(f"ÙØ´Ù„ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¥Ø®ÙØ§Ù‚ {failure_file}: {e}")
            
            return patterns
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ø®ÙØ§Ù‚Ø§Øª: {e}")
            return []
    
    def create_backup(self) -> bool:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            backup_name = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            backup_path = self.base_path / "backups" / backup_name
            
            # Ù†Ø³Ø® Ø¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            shutil.copytree(self.base_path, backup_path, 
                          ignore=shutil.ignore_patterns("backups"))
            
            # Ù†Ø³Ø® Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹Ø§Øª ÙˆØ§Ù„Ù„ÙˆØ­Ø©
            if self.meetings_path.exists():
                shutil.copytree(self.meetings_path, backup_path / "meetings_data")
            
            if self.board_path.exists():
                shutil.copytree(self.board_path, backup_path / "board_data")
            
            self.logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_name}")
            return True
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return False
    
    def restore_from_backup(self, backup_name: str) -> bool:
        """Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù…Ù† Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        try:
            backup_path = self.base_path / "backups" / backup_name
            
            if not backup_path.exists():
                self.logger.error(f"Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {backup_name}")
                return False
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©
            current_backup = f"pre_restore_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.create_backup()
            
            # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            # (ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø£ÙƒØ«Ø± Ø­Ø°Ø±Ø§Ù‹)
            
            self.logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_name}")
            return True
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return False
    
    def get_memory_statistics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            stats = self.memory_index.copy()
            
            # Ø¥Ø¶Ø§ÙØ© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            stats["storage_size_mb"] = self._calculate_storage_size()
            stats["backup_count"] = len(list((self.base_path / "backups").glob("*")))
            
            return stats
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
            return {}
    
    def _calculate_storage_size(self) -> float:
        """Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª"""
        try:
            total_size = 0
            
            for path in [self.base_path, self.meetings_path, self.board_path]:
                if path.exists():
                    for file_path in path.rglob("*"):
                        if file_path.is_file():
                            total_size += file_path.stat().st_size
            
            return round(total_size / (1024 * 1024), 2)
            
        except Exception as e:
            self.logger.warning(f"ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ†: {e}")
            return 0.0
    
    def cleanup_old_data(self, days_to_keep: int = 30) -> bool:
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        try:
            cutoff_date = datetime.now(timezone.utc).timestamp() - (days_to_keep * 24 * 60 * 60)
            cleaned_count = 0
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            backups_path = self.base_path / "backups"
            if backups_path.exists():
                for backup_dir in backups_path.iterdir():
                    if backup_dir.is_dir():
                        backup_time = backup_dir.stat().st_mtime
                        if backup_time < cutoff_date:
                            shutil.rmtree(backup_dir)
                            cleaned_count += 1
            
            self.logger.info(f"ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ {cleaned_count} Ø¹Ù†ØµØ± Ù‚Ø¯ÙŠÙ…")
            return True
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {e}")
            return False